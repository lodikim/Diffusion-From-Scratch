Epoch 0 | step 000 Loss: 0.8089208602905273 
Epoch 2 | step 000 Loss: 0.1696501225233078 
Epoch 4 | step 000 Loss: 0.16921451687812805 
Epoch 6 | step 000 Loss: 0.13640746474266052 
Epoch 8 | step 000 Loss: 0.13373228907585144 
Epoch 10 | step 000 Loss: 0.15093068778514862 
Epoch 12 | step 000 Loss: 0.15135791897773743 
Epoch 14 | step 000 Loss: 0.15062518417835236 
Epoch 16 | step 000 Loss: 0.14353621006011963 
Epoch 18 | step 000 Loss: 0.1355452686548233 
Epoch 20 | step 000 Loss: 0.15502125024795532 
Epoch 22 | step 000 Loss: 0.12153381109237671 
Epoch 24 | step 000 Loss: 0.13499179482460022 
Epoch 26 | step 000 Loss: 0.14158254861831665 
Epoch 28 | step 000 Loss: 0.14142045378684998 
Epoch 30 | step 000 Loss: 0.151987686753273 
Epoch 32 | step 000 Loss: 0.14169469475746155 
Epoch 34 | step 000 Loss: 0.13485901057720184 
Epoch 36 | step 000 Loss: 0.1409301459789276 
Epoch 38 | step 000 Loss: 0.13634179532527924 
Epoch 40 | step 000 Loss: 0.13286235928535461 
E:\Diffusion\diffusion-from-scratch\sampling.py:43: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.  
  plt.figure(figsize=(15,15))
Epoch 42 | step 000 Loss: 0.1307428479194641 
Epoch 44 | step 000 Loss: 0.15882264077663422 
Epoch 46 | step 000 Loss: 0.13285402953624725 
Epoch 48 | step 000 Loss: 0.1355012208223343 
Epoch 50 | step 000 Loss: 0.1411401927471161 
Epoch 52 | step 000 Loss: 0.13347849249839783 
Epoch 54 | step 000 Loss: 0.14364179968833923 
Epoch 56 | step 000 Loss: 0.12814311683177948 
Epoch 58 | step 000 Loss: 0.13214395940303802 
Epoch 60 | step 000 Loss: 0.12387657165527344 
Epoch 62 | step 000 Loss: 0.14196398854255676 
Epoch 64 | step 000 Loss: 0.15005788207054138 
Epoch 66 | step 000 Loss: 0.15518002212047577 
Epoch 68 | step 000 Loss: 0.1314372420310974
Epoch 70 | step 000 Loss: 0.15317146480083466
Epoch 72 | step 000 Loss: 0.12778934836387634
Epoch 74 | step 000 Loss: 0.14855259656906128
Epoch 76 | step 000 Loss: 0.12246324867010117
Epoch 78 | step 000 Loss: 0.1358194798231125
Epoch 80 | step 000 Loss: 0.14876602590084076
Epoch 82 | step 000 Loss: 0.12981058657169342
Epoch 84 | step 000 Loss: 0.12529440224170685
Epoch 86 | step 000 Loss: 0.1295551359653473
Epoch 88 | step 000 Loss: 0.13443773984909058
Epoch 90 | step 000 Loss: 0.13749723136425018
Epoch 92 | step 000 Loss: 0.14772525429725647
Epoch 94 | step 000 Loss: 0.12230734527111053
Epoch 96 | step 000 Loss: 0.13591910898685455
Epoch 98 | step 000 Loss: 0.13117444515228271